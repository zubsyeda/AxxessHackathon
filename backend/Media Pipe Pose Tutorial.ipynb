{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mediapipe in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (0.10.9)\n",
      "Requirement already satisfied: opencv-python in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: numpy in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (3.8.3)\n",
      "Requirement already satisfied: absl-py in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (4.49.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/zubiya_syeda/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1708247571.859278       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-22.1.29), renderer: Intel(R) Iris(TM) Plus Graphics 645\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mmp_drawing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDrawingSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcolor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mthickness\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcircle_radius\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      DrawingSpec(color: Tuple[int, int, int] = (224, 224, 224), thickness: int = 2, circle_radius: int = 2)\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mDrawingSpec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;31m# Color for drawing the annotation. Default to the white color.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWHITE_COLOR\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;31m# Thickness for drawing the annotation. Default to 2 pixels.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mthickness\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;31m# Circle radius. Default to 2 pixels.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0mcircle_radius\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Library/Python/3.9/lib/python/site-packages/mediapipe/python/solutions/drawing_utils.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "mp_drawing.DrawingSpec??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://www.kaggle.com/code/venkatkumar001/yoga-pose-recognition-mediapipe\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    '''\n",
    "    This function calculates angle between three different landmarks.\n",
    "    Args:\n",
    "        landmark1: The first landmark containing the x,y and z coordinates.\n",
    "        landmark2: The second landmark containing the x,y and z coordinates.\n",
    "        landmark3: The third landmark containing the x,y and z coordinates.\n",
    "    Returns:\n",
    "        angle: The calculated angle between the three landmarks.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    \n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "    \n",
    "    # Return the calculated angle.\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated angle is 166.26373169437744\n"
     ]
    }
   ],
   "source": [
    "# Calculate the angle between the three landmarks.\n",
    "angle = calculateAngle((558, 326, 0), (642, 333, 0), (718, 321, 0))\n",
    "\n",
    "# Display the calculated angle.\n",
    "print(f'The calculated angle is {angle}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasify Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPose(landmarks, output_image, display=False):\n",
    "    '''\n",
    "    This function classifies yoga poses depending upon the angles of various body joints.\n",
    "    Args:\n",
    "        landmarks: A list of detected landmarks of the person whose pose needs to be classified.\n",
    "        output_image: A image of the person with the detected pose landmarks drawn.\n",
    "        display: A boolean value that is if set to true the function displays the resultant image with the pose label \n",
    "        written on it and returns nothing.\n",
    "    Returns:\n",
    "        output_image: The image with the detected pose landmarks drawn and pose label written.\n",
    "        label: The classified pose label of the person in the output_image.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Initialize the label of the pose. It is not known at this stage.\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Specify the color (Red) with which the label will be written on the image.\n",
    "    color = (0, 0, 255)\n",
    "    \n",
    "    # Calculate the required angles.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Get the angle between the left shoulder, elbow and wrist points. \n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "    # Get the angle between the right shoulder, elbow and wrist points. \n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n",
    "    \n",
    "    # Get the angle between the left elbow, shoulder and hip points. \n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "    # Get the angle between the right hip, shoulder and elbow points. \n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    # Get the angle between the left hip, knee and ankle points. \n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right hip, knee and ankle points \n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Check if it is the warrior II pose or the T pose.\n",
    "    # As for both of them, both arms should be straight and shoulders should be at the specific angle.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Check if the both arms are straight.\n",
    "    if left_elbow_angle > 165 and left_elbow_angle < 195 and right_elbow_angle > 165 and right_elbow_angle < 195:\n",
    "\n",
    "        # Check if shoulders are at the required angle.\n",
    "        if left_shoulder_angle > 80 and left_shoulder_angle < 110 and right_shoulder_angle > 80 and right_shoulder_angle < 110:\n",
    "\n",
    "    # Check if it is the warrior II pose.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Check if one leg is straight.\n",
    "            if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195:\n",
    "\n",
    "                # Check if the other leg is bended at the required angle.\n",
    "                if left_knee_angle > 90 and left_knee_angle < 120 or right_knee_angle > 90 and right_knee_angle < 120:\n",
    "\n",
    "                    # Specify the label of the pose that is Warrior II pose.\n",
    "                    label = 'Warrior II Pose' \n",
    "                        \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Check if it is the T pose.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Check if both legs are straight\n",
    "            if left_knee_angle > 160 and left_knee_angle < 195 and right_knee_angle > 160 and right_knee_angle < 195:\n",
    "\n",
    "                # Specify the label of the pose that is tree pose.\n",
    "                label = 'T Pose'\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Check if it is the tree pose.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Check if one leg is straight\n",
    "    if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195:\n",
    "\n",
    "        # Check if the other leg is bended at the required angle.\n",
    "        if left_knee_angle > 315 and left_knee_angle < 335 or right_knee_angle > 25 and right_knee_angle < 45:\n",
    "\n",
    "            # Specify the label of the pose that is tree pose.\n",
    "            label = 'Tree Pose'\n",
    "                \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Check if the pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        \n",
    "        # Update the color (to green) with which the label will be written on the image.\n",
    "        color = (0,0,255)  \n",
    "    \n",
    "    # Write the label on the output image. \n",
    "    cv2.putText(output_image, label, (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, color, 5)\n",
    "    \n",
    "    # Check if the resultant image is specified to be displayed.\n",
    "    if display:\n",
    "    \n",
    "        # Display the resultant image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Return the output image and the classified label.\n",
    "        print(label)\n",
    "        # return output_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read a sample image and perform pose classification on it.\n",
    "# image = cv2.imread('./assets/tree.jpg')\n",
    "# output_image, landmarks = detectPose(image, pose, display=False)\n",
    "# if landmarks:\n",
    "#     classifyPose(landmarks, output_image, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Determining Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1708247574.997527       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-22.1.29), renderer: Intel(R) Iris(TM) Plus Graphics 645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X hits\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n",
      "X TREE POSE\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    label = 'Unknown'\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            # classifyPose(image, landmarks)\n",
    "            # left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "            #                           landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "            #                           landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "            # # Get the angle between the right shoulder, elbow and wrist points. \n",
    "            # right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "            #                                 landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "            #                                 landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n",
    "            \n",
    "            # # Get the angle between the left elbow, shoulder and hip points. \n",
    "            # left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "            #                                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "            #                                     landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "            # # Get the angle between the right hip, shoulder and elbow points. \n",
    "            # right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "            #                                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "            #                                     landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "            # # Get the angle between the left hip, knee and ankle points. \n",
    "            # left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "            #                                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "            #                                 landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "            # # Get the angle between the right hip, knee and ankle points \n",
    "            # right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "            #                                 landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "            #                                 landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "            \n",
    "            # if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195:\n",
    "            #     # Check if the other leg is bended at the required angle.\n",
    "            #     if left_knee_angle > 315 and left_knee_angle < 335 or right_knee_angle > 25 and right_knee_angle < 45:\n",
    "            #         # Specify the label of the pose that is tree pose.\n",
    "            #         print('Tree Pose')\n",
    "            #         label = 'Tree Pose'\n",
    "            \n",
    "            # print(landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "            if landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x >= 0.3 and landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x <= 0.4:\n",
    "                print(\"X hits\")\n",
    "                if landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y >= 0.5 and landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y <= 0.6:\n",
    "                    # print()\n",
    "                    print(\"Warrior Pose\")\n",
    "                    label = 'Warrior Pose'\n",
    "                    cv2.putText(image, \"Warrior Pose\", (10, 40),cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 0), 5)\n",
    "                        \n",
    "            # print(landmarks[0].z\n",
    "            if landmarks[0].x >= 0.50 and landmarks[0].x <= 0.70:\n",
    "                print(\"X TREE POSE\")\n",
    "                if landmarks[0].y >= 0.09 and landmarks[0].y <= 0.15:\n",
    "                    print(\"Tree Pose\")\n",
    "                    label = 'Tree Pose'\n",
    "                    cv2.putText(image, 'Tree Pose', (10, 40),cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 0), 5)\n",
    "\n",
    "            \n",
    "                    \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        cv2.putText(image, label, (10, 40),cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 0), 5)\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- PositionStorage = [\n",
    "    \"Tree Pose\": [x: 6, y: 7, z: 8],\n",
    "    \"Hand\": [x: 2, y: ]\n",
    "    ] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838929176330566"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2469795048236847"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5096468329429626"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4552144408226013, 0.1455259770154953],\n",
       " [0.47967880964279175, 0.6548539996147156],\n",
       " [0.5096468329429626, 0.9625184535980225])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder, elbow, wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.18661480302026"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 314)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(elbow, [640, 480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1708247596.703551       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-22.1.29), renderer: Intel(R) Iris(TM) Plus Graphics 645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_pose\u001b[38;5;241m.\u001b[39mPose(min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pose:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m----> 5\u001b[0m         ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# Recolor image to RGB\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
